{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: PREPARE DATASET\n",
      "INFO: Align face\n",
      "Please wait...\n",
      "Aligned face save at dataset/aligned\n",
      "INFO: Remove face mask region\n",
      "Please wait...\n",
      "Masked face save at dataset/masked\n",
      "INFO: Combine dataset\n",
      "Please wait...\n",
      "Combine dataset save at dataset/combine\n"
     ]
    }
   ],
   "source": [
    "from train import prepare_dataset\n",
    "\n",
    "INPUT_DIR = ''\n",
    "ALIGNED_DIR = 'dataset/aligned'\n",
    "MASKED_DIR = 'dataset/masked'\n",
    "COMBINE_DIR = 'dataset/combine'\n",
    "\n",
    "print('INFO: PREPARE DATASET')\n",
    "\n",
    "print('INFO: Align face')\n",
    "print('Please wait...')\n",
    "prepare_dataset.aligned_dataset(INPUT_DIR, ALIGNED_DIR)\n",
    "print('Aligned face save at ' + ALIGNED_DIR)\n",
    "print('INFO: Remove face mask region')\n",
    "print('Please wait...')\n",
    "prepare_dataset.masked_dataset(ALIGNED_DIR, MASKED_DIR)\n",
    "print('Masked face save at ' + MASKED_DIR)\n",
    "print('INFO: Combine dataset')\n",
    "print('Please wait...')\n",
    "prepare_dataset.combine_dataset(ALIGNED_DIR, MASKED_DIR, COMBINE_DIR)\n",
    "print('Combine dataset save at ' + COMBINE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.metrics import CategoricalAccuracy\n",
    "import os\n",
    "from models.feature_extraction_model.inceptionresnetv2 import get_train_model\n",
    "\n",
    "\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "DATA_DIR = COMBINE_DIR\n",
    "RESULTS_DIR = 'train/results'\n",
    "\n",
    "print('INFO: TRAIN MODEL')\n",
    "\n",
    "print('INFO: Dataset pre_processing')\n",
    "print('Please wait...')\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    label_mode = 'categorical',\n",
    "    image_size=(299,299),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    subset = \"training\",\n",
    "    validation_split = 0.2,\n",
    "    seed = 23,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    label_mode = 'categorical',\n",
    "    image_size=(299,299),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    subset = \"validation\",\n",
    "    validation_split = 0.2,\n",
    "    seed = 23,\n",
    ")\n",
    "\n",
    "num_class = len(os.listdir(DATA_DIR))\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=BATCH_SIZE)\n",
    "val_ds = val_ds.prefetch(buffer_size=BATCH_SIZE)\n",
    "\n",
    "# data_augmentation = keras.layers.RandomZoom(0.2)\n",
    "# augmented_train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "normalization_layer = keras.layers.Rescaling(1./255)\n",
    "normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "normalized_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "print('INFO: Create model')\n",
    "model = get_train_model(num_class)\n",
    "\n",
    "print('INFO: Compile model')\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=[CategoricalAccuracy()])\n",
    "\n",
    "# initial_learning_rate = 0.001\n",
    "\n",
    "# def lr_exp_decay(epoch, lr):\n",
    "#     k = 0.1\n",
    "#     return initial_learning_rate * math.exp(-k*epoch)\n",
    "\n",
    "callbacks = [\n",
    "    # keras.callbacks.LearningRateScheduler(lr_exp_decay, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(os.path.join(RESULTS_DIR, \"check_point.h5\"), monitor='categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='max'),\n",
    "]\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    normalized_train_ds,\n",
    "    epochs = EPOCHS,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = normalized_val_ds,\n",
    ")\n",
    "\n",
    "model.save(os.path.join(RESULTS_DIR, \"final.h5\"))\n",
    "\n",
    "epochs = [i for i in range(1, len(history.history['loss'])+1)]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(epochs, history.history['categorical_accuracy'], color='blue', label=\"training_accuracy\")\n",
    "plt.legend(loc='best')\n",
    "plt.title('training')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"acc.png\"), bbox_inches='tight')\n",
    "# plt.show()\n",
    "plt.figure(2)\n",
    "plt.plot(epochs, history.history['loss'], color='red', label=\"training_loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.title('training')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"loss.png\"), bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert trained model to embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.cvt_trained_md_2_embedding_md import cvt_trained_md_2_embedding_md\n",
    "\n",
    "model = cvt_trained_md_2_embedding_md('train/results/check_point.h5', 'models/feature_extraction_model/inceptionresnetv2_512_weights.h5')\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "226ddcefb96984e9d15c92f419c0c41ae3421f8fff2653b65891dfa4f02f6cc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
