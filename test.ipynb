{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import prepare_dataset\n",
    "\n",
    "INPUT_DIR = ''\n",
    "ALIGNED_DIR = 'test_dataset/aligned'\n",
    "MASKED_DIR = 'test_dataset/masked'\n",
    "COMBINE_DIR = 'test_dataset/combine'\n",
    "\n",
    "print('INFO: PREPARE DATASET')\n",
    "\n",
    "print('INFO: Align face')\n",
    "print('Please wait...')\n",
    "prepare_dataset.aligned_dataset(INPUT_DIR, ALIGNED_DIR)\n",
    "print('Aligned face save at ' + ALIGNED_DIR)\n",
    "print('INFO: Remove face mask region')\n",
    "print('Please wait...')\n",
    "prepare_dataset.masked_dataset(ALIGNED_DIR, MASKED_DIR)\n",
    "print('Masked face save at ' + MASKED_DIR)\n",
    "print('INFO: Combine dataset')\n",
    "print('Please wait...')\n",
    "prepare_dataset.combine_dataset(ALIGNED_DIR, MASKED_DIR, COMBINE_DIR)\n",
    "print('Combine dataset save at ' + COMBINE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.evaluate import calculate_accuracy\n",
    "from utils.featureExtraction import feature_extraction\n",
    "import os\n",
    "import numpy as np\n",
    "from utils.classification import predict_cosine\n",
    "\n",
    "\n",
    "DATASET_DIR = ALIGNED_DIR\n",
    "THRESHOLDS = [0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "split_ratio = 0.2\n",
    "\n",
    "print('Runnning forward pass on {DATASET_DIR} images')\n",
    "\n",
    "embs = []\n",
    "image_paths = []\n",
    "labels = []\n",
    "for fld_name in os.listdir(DATASET_DIR):\n",
    "    image_path = os.path.join(DATASET_DIR, fld_name)\n",
    "    image_paths.append(image_path)\n",
    "    labels.append(fld_name)\n",
    "    embs.append(feature_extraction(image_path))\n",
    "\n",
    "num_class = len(labels)\n",
    "image_indices = np.arange(num_class)\n",
    "np.random.shuffle(image_indices)\n",
    "split = int(round(num_class*(1-split_ratio)))\n",
    "\n",
    "train_embs = [embs[i] for i in image_indices[0:split]]\n",
    "train_labels = [labels[i] for i in image_indices[0:split]]\n",
    "test_embs = [embs[i] for i in image_indices[split:-1]]\n",
    "test_labels = [labels[i] for i in image_indices[0:split]]\n",
    "\n",
    "max_indexes = []\n",
    "max_probs = []\n",
    "actual_issame_list = []\n",
    "\n",
    "for i, audit_emb in enumerate(test_embs):\n",
    "    max_index, max_prob = predict_cosine(audit_emb, train_embs)\n",
    "    actual_issame = True if train_labels[max_index] == test_labels[i] else False\n",
    "    max_indexes.append(max_index)\n",
    "    max_probs.append(max_prob)\n",
    "    actual_issame_list.append(actual_issame)\n",
    "\n",
    "for threshold in THRESHOLDS:\n",
    "    print('........................')\n",
    "    print('Evaluate threshold: {threshold}')\n",
    "    acc, val_rate, error_rate = calculate_accuracy(threshold, max_probs, actual_issame_list)\n",
    "    print('Accuracy: {acc}')\n",
    "    print('Validation rate: {val_rate}')\n",
    "    print('Error Rate: {error_rate}')\n",
    "\n",
    "                \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
